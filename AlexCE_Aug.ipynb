{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardboard = []\n",
    "for i in range(1,404):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/cardboard/cardboard\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    cardboard.append(X)\n",
    "cardboard = np.array(cardboard)\n",
    "cardboard = np.take(cardboard,np.random.permutation(cardboard.shape[0]),axis=0)\n",
    "print(cardboard.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = []\n",
    "for i in range(1,502):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/glass/glass\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    glass.append(X)\n",
    "glass = np.array(glass)\n",
    "glass = np.take(glass,np.random.permutation(glass.shape[0]),axis=0)\n",
    "print(glass.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal = []\n",
    "for i in range(1,411):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/metal/metal\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    metal.append(X)\n",
    "metal = np.array(metal)\n",
    "metal = np.take(metal,np.random.permutation(metal.shape[0]),axis=0)\n",
    "print(metal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = []\n",
    "for i in range(1,595):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/paper/paper\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    paper.append(X)\n",
    "paper = np.array(paper)\n",
    "paper = np.take(paper,np.random.permutation(paper.shape[0]),axis=0)\n",
    "print(paper.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plastic = []\n",
    "for i in range(1,483):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/plastic/plastic\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    plastic.append(X)\n",
    "plastic = np.array(plastic)\n",
    "plastic = np.take(plastic,np.random.permutation(plastic.shape[0]),axis=0)\n",
    "print(plastic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash = []\n",
    "for i in range(1,138):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/trash/trash\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    trash.append(X)\n",
    "trash = np.array(trash)\n",
    "trash = np.take(trash,np.random.permutation(trash.shape[0]),axis=0)\n",
    "print(trash.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.vstack((cardboard[:302,:,:,:],glass[:376,:,:,:],metal[:307,:,:,:],\n",
    "                    paper[:445,:,:,:],plastic[:361,:,:,:],trash[:103,:,:,:]))\n",
    "test_X = np.vstack((cardboard[302:,:,:,:],glass[376:,:,:,:],metal[307:,:,:,:],\n",
    "                   paper[445:,:,:,:],plastic[361:,:,:,:],trash[103:,:,:,:]))\n",
    "train_Y = np.zeros((6,train_X.shape[0]))\n",
    "test_Y = np.zeros((6,test_X.shape[0]))\n",
    "for i in range(train_X.shape[0]):\n",
    "    if(i<302):\n",
    "        train_Y[0][i] = 1\n",
    "    elif(i<678):\n",
    "        train_Y[1][i] = 1\n",
    "    elif(i<985):\n",
    "        train_Y[2][i] = 1\n",
    "    elif(i<1430):\n",
    "        train_Y[3][i] = 1\n",
    "    elif(i<1791):\n",
    "        train_Y[4][i] = 1\n",
    "    else:\n",
    "        train_Y[5][i] = 1\n",
    "for i in range(test_X.shape[0]):\n",
    "    if(i<101):\n",
    "        test_Y[0][i] = 1\n",
    "    elif(i<226):\n",
    "        test_Y[1][i] = 1\n",
    "    elif(i<329):\n",
    "        test_Y[2][i] = 1\n",
    "    elif(i<478):\n",
    "        test_Y[3][i] = 1\n",
    "    elif(i<599):\n",
    "        test_Y[4][i] = 1\n",
    "    else:\n",
    "        test_Y[5][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_re = test_X\n",
    "test_Y_re = test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1013)\n",
    "train_perm = np.random.permutation(train_X.shape[0])\n",
    "train_X = np.take(train_X,train_perm,axis=0)\n",
    "print(train_X.shape)\n",
    "train_Y = np.take(train_Y,train_perm,axis=1)\n",
    "print(train_Y.shape)\n",
    "np.random.seed(901)\n",
    "test_perm = np.random.permutation(test_X.shape[0])\n",
    "test_X = np.take(test_X,test_perm,axis=0)\n",
    "print(test_X.shape)\n",
    "test_Y = np.take(test_Y,test_perm,axis=1)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,height_shift_range=0.1, rotation_range=45, zoom_range=0.1,\n",
    "    horizontal_flip=True,vertical_flip=True)\n",
    "train_gen.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlexNetCE(input_shape = (227, 227, 3), classes = 6):\n",
    "    X_input = tf.keras.Input(input_shape)\n",
    "    X = X_input\n",
    "    X = tf.keras.layers.Conv2D(96, (11, 11), strides = (4, 4), activation = \"relu\", name = 'conv1')(X)\n",
    "    X = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = tf.keras.layers.Conv2D(256, (5, 5), padding = \"same\",activation = \"relu\", name = 'conv2')(X)\n",
    "    X = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = 'bn_conv2')(X)\n",
    "    X = tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\",activation = \"relu\", name = 'conv5')(X)\n",
    "    X = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = tf.keras.layers.Dense(4096, activation = \"relu\", name='fc' + str(1))(X)\n",
    "    X = tf.keras.layers.Dense(4096, activation = \"relu\", name='fc' + str(2))(X)\n",
    "    X = tf.keras.layers.Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
    "       \n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs = X_input, outputs = X, name='ALEXNETCE')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNetCE()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000005), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "for i in range(20):\n",
    "    print(\"Training Process \"+str(len(train_loss)))\n",
    "    history = model.fit(train_gen.flow(train_X, train_Y.T, batch_size=32),steps_per_epoch=60,epochs=1)\n",
    "    print(\"Test Result \"+str(len(train_loss)))\n",
    "    preds = model.evaluate(test_X, test_Y.T)\n",
    "    print (\"Loss = \" + str(preds[0]))\n",
    "    print (\"Test Accuracy = \" + str(preds[1]))\n",
    "    train_loss.append(history.history[\"loss\"][0])\n",
    "    train_acc.append(history.history[\"accuracy\"][0])\n",
    "    test_loss.append(preds[0])\n",
    "    test_acc.append(preds[1])\n",
    "plt.plot(train_loss)\n",
    "plt.show()\n",
    "plt.plot(test_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Training Process \"+str(len(train_loss)))\n",
    "    history = model.fit(train_gen.flow(train_X, train_Y.T, batch_size=32),steps_per_epoch=60,epochs=1)\n",
    "    print(\"Test Result \"+str(len(train_loss)))\n",
    "    preds = model.evaluate(test_X, test_Y.T)\n",
    "    print (\"Loss = \" + str(preds[0]))\n",
    "    print (\"Test Accuracy = \" + str(preds[1]))\n",
    "    train_loss.append(history.history[\"loss\"][0])\n",
    "    train_acc.append(history.history[\"accuracy\"][0])\n",
    "    test_loss.append(preds[0])\n",
    "    test_acc.append(preds[1])\n",
    "plt.plot(train_loss)\n",
    "plt.show()\n",
    "plt.plot(test_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Training Process \"+str(len(train_loss)))\n",
    "    history = model.fit(train_X, train_Y.T,batch_size=32,epochs=1)\n",
    "    print(\"Test Result \"+str(len(train_loss)))\n",
    "    preds = model.evaluate(test_X, test_Y.T)\n",
    "    print (\"Loss = \" + str(preds[0]))\n",
    "    print (\"Test Accuracy = \" + str(preds[1]))\n",
    "    train_loss.append(history.history[\"loss\"][0])\n",
    "    train_acc.append(history.history[\"accuracy\"][0])\n",
    "    test_loss.append(preds[0])\n",
    "    test_acc.append(preds[1])\n",
    "plt.plot(train_loss)\n",
    "plt.show()\n",
    "plt.plot(test_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Training Process \"+str(len(train_loss)))\n",
    "    history = model.fit(train_X, train_Y.T,batch_size=32,epochs=1)\n",
    "    print(\"Test Result \"+str(len(train_loss)))\n",
    "    preds = model.evaluate(test_X, test_Y.T)\n",
    "    print (\"Loss = \" + str(preds[0]))\n",
    "    print (\"Test Accuracy = \" + str(preds[1]))\n",
    "    train_loss.append(history.history[\"loss\"][0])\n",
    "    train_acc.append(history.history[\"accuracy\"][0])\n",
    "    test_loss.append(preds[0])\n",
    "    test_acc.append(preds[1])\n",
    "plt.plot(train_loss)\n",
    "plt.show()\n",
    "plt.plot(test_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Training Process \"+str(len(train_loss)))\n",
    "    history = model.fit(train_X, train_Y.T,batch_size=32,epochs=1)\n",
    "    print(\"Test Result \"+str(len(train_loss)))\n",
    "    preds = model.evaluate(test_X, test_Y.T)\n",
    "    print (\"Loss = \" + str(preds[0]))\n",
    "    print (\"Test Accuracy = \" + str(preds[1]))\n",
    "    train_loss.append(history.history[\"loss\"][0])\n",
    "    train_acc.append(history.history[\"accuracy\"][0])\n",
    "    test_loss.append(preds[0])\n",
    "    test_acc.append(preds[1])\n",
    "plt.plot(train_loss)\n",
    "plt.show()\n",
    "plt.plot(test_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = [0,0,0,0,0,0]\n",
    "mislabel = np.zeros((6,6))\n",
    "prediction = model.predict(test_X_re)\n",
    "for i in range(test_X_re.shape[0]):\n",
    "    if(test_Y_re[np.argmax(prediction,axis=1)[i],i] == 0):\n",
    "        if(i<101):\n",
    "            error[0] = error[0]+1\n",
    "            mislabel[0][np.argmax(prediction,axis=1)[i]] += 1\n",
    "        elif(i<226):\n",
    "            error[1] = error[1]+1\n",
    "            mislabel[1][np.argmax(prediction,axis=1)[i]] += 1\n",
    "        elif(i<329):\n",
    "            error[2] = error[2]+1\n",
    "            mislabel[2][np.argmax(prediction,axis=1)[i]] += 1\n",
    "        elif(i<478):\n",
    "            error[3] = error[3]+1\n",
    "            mislabel[3][np.argmax(prediction,axis=1)[i]] += 1\n",
    "        elif(i<599):\n",
    "            error[4] = error[4]+1\n",
    "            mislabel[4][np.argmax(prediction,axis=1)[i]] += 1\n",
    "        else:\n",
    "            error[5] = error[5]+1\n",
    "            mislabel[5][np.argmax(prediction,axis=1)[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.array([101,125,103,149,121,34])\n",
    "error = np.array(error)\n",
    "error = np.divide(error,total)\n",
    "print(\"% of mislabeled cardboard: \"+str(error[0]))\n",
    "print(\"Mostly mislabeled as: \"+str(np.argmax(mislabel,axis=0)[0]))\n",
    "print(\"% of mislabeled glass: \"+str(error[1]))\n",
    "print(\"Mostly mislabeled as: \"+str(np.argmax(mislabel,axis=0)[1]))\n",
    "print(\"% of mislabeled metal: \"+str(error[2]))\n",
    "print(\"Mostly mislabeled as: \"+str(np.argmax(mislabel,axis=0)[2]))\n",
    "print(\"% of mislabeled paper: \"+str(error[3]))\n",
    "print(\"Mostly mislabeled as: \"+str(np.argmax(mislabel,axis=0)[3]))\n",
    "print(\"% of mislabeled plastic: \"+str(error[4]))\n",
    "print(\"Mostly mislabeled as: \"+str(np.argmax(mislabel,axis=0)[4]))\n",
    "print(\"% of mislabeled trash: \"+str(error[5]))\n",
    "print(\"Mostly mislabeled as: \"+str(np.argmax(mislabel,axis=0)[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('train_loss_aug_p.txt', 'w')\n",
    "#for i in train_loss:\n",
    "#    f.write(str(i))\n",
    "#    f.write(\"\\n\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('test_loss_aug_p.txt', 'w')\n",
    "#for i in test_loss:\n",
    "#    f.write(str(i))\n",
    "#    f.write(\"\\n\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('train_acc_aug_p.txt', 'w')\n",
    "#for i in train_acc:\n",
    "#    f.write(str(i))\n",
    "#    f.write(\"\\n\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('test_acc_aug_p.txt', 'w')\n",
    "#for i in test_acc:\n",
    "#    f.write(str(i))\n",
    "#    f.write(\"\\n\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('error_aug.txt', 'w')\n",
    "#for i in error:\n",
    "#    f.write(str(i))\n",
    "#    f.write(\"\\n\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
